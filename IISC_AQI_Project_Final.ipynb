{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgy1625XagEliBmjtffbsA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johny85/World-of-Scripts/blob/master/IISC_AQI_Project_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0G4QkEvb2tv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Step 1: Read all the CSV files and combine them into a single DataFrame.\n",
        "file_list = glob.glob('*.csv')\n",
        "\n",
        "# Initialize an empty list to store the DataFrames.\n",
        "df_list = []\n",
        "\n",
        "# Loop through each file, read it into a DataFrame and add a 'City' column.\n",
        "for file in file_list:\n",
        "    city_name = file.replace('.csv', '')\n",
        "    df = pd.read_csv(file)\n",
        "    df['City'] = city_name\n",
        "    df_list.append(df)\n",
        "\n",
        "# Concatenate all the DataFrames into one.\n",
        "combined_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Step 2: Standardize column names.\n",
        "new_columns = {\n",
        "    'PM2.5 (µg/m³)': 'pm2_5',\n",
        "    'PM10 (µg/m³)': 'pm10',\n",
        "    'NO (µg/m³)': 'no',\n",
        "    'NO2 (µg/m³)': 'no2',\n",
        "    'NOx (ppb)': 'nox',\n",
        "    'NH3 (µg/m³)': 'nh3',\n",
        "    'SO2 (µg/m³)': 'so2',\n",
        "    'CO (mg/m³)': 'co',\n",
        "    'Ozone (µg/m³)': 'ozone',\n",
        "    'Benzene (µg/m³)': 'benzene',\n",
        "    'Toluene (µg/m³)': 'toluene',\n",
        "    'Xylene (µg/m³)': 'xylene',\n",
        "    'O Xylene (µg/m³)': 'o_xylene',\n",
        "    'Eth-Benzene (µg/m³)': 'eth_benzene',\n",
        "    'MP-Xylene (µg/m³)': 'mp_xylene',\n",
        "    'AT (°C)': 'temp_c',\n",
        "    'RH (%)': 'rh_percent',\n",
        "    'WS (m/s)': 'ws_m_s',\n",
        "    'WD (deg)': 'wd_deg',\n",
        "    'RF (mm)': 'rf_mm',\n",
        "    'TOT-RF (mm)': 'tot_rf_mm',\n",
        "    'SR (W/mt2)': 'sr_w_mt2',\n",
        "    'BP (mmHg)': 'bp_mmHg',\n",
        "    'VWS (m/s)': 'vws_m_s',\n",
        "    'Timestamp': 'timestamp'\n",
        "}\n",
        "combined_df.rename(columns=new_columns, inplace=True)\n",
        "\n",
        "# Step 3: Handle missing values and convert data types.\n",
        "# Replace common representations of missing data with pandas' NaN.\n",
        "combined_df.replace(['', 'NA'], pd.NA, inplace=True)\n",
        "\n",
        "# Convert 'timestamp' to datetime and set it as the index.\n",
        "# Use errors='coerce' to turn invalid parsing into NaT (Not a Time).\n",
        "# Use format='mixed' and dayfirst=True to handle potential inconsistencies in timestamp format.\n",
        "combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'], errors='coerce', format='mixed', dayfirst=True)\n",
        "combined_df.set_index('timestamp', inplace=True)\n",
        "\n",
        "# Convert all relevant columns to numeric type, coercing errors to NaN.\n",
        "for col in combined_df.columns:\n",
        "    if col not in ['City']:\n",
        "        combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
        "\n",
        "# Step 4: Check for and drop duplicates.\n",
        "duplicates = combined_df.duplicated().sum()\n",
        "print(f\"Found {duplicates} duplicate rows.\")\n",
        "if duplicates > 0:\n",
        "    combined_df.drop_duplicates(inplace=True)\n",
        "    print(\"Dropped duplicate rows.\")\n",
        "\n",
        "\n",
        "combined_df.info()\n",
        "\n",
        "# Step 5: Resample the data to a daily average.\n",
        "# Group by city and then resample\n",
        "daily_df = combined_df.groupby('City').resample('D').mean()\n",
        "\n",
        "# The grouping creates a multi-index. Reset the index to make 'City' a column again.\n",
        "daily_df.reset_index(inplace=True)\n",
        "\n",
        "# You can save this cleaned and resampled data to a new CSV file.\n",
        "daily_df.to_csv('aqi_data.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(\"Head of the cleaned and resampled DataFrame:\")\n",
        "print(daily_df.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "daily_df.info()"
      ]
    }
  ]
}