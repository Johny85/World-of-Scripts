{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQMzJrnZNfuZAocWcsHNuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johny85/World-of-Scripts/blob/master/IISC_AQI_Project_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0G4QkEvb2tv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Step 1: Read all the CSV files and combine them into a single DataFrame.\n",
        "file_list = glob.glob('*.csv')\n",
        "\n",
        "# Initialize an empty list to store the DataFrames.\n",
        "df_list = []\n",
        "\n",
        "# Loop through each file, read it into a DataFrame and add a 'City' column.\n",
        "for file in file_list:\n",
        "    city_name = file.replace('.csv', '')\n",
        "    df = pd.read_csv(file)\n",
        "    df['City'] = city_name\n",
        "    df_list.append(df)\n",
        "\n",
        "# Concatenate all the DataFrames into one.\n",
        "combined_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Step 2: Standardize column names.\n",
        "new_columns = {\n",
        "    'PM2.5 (µg/m³)': 'pm2_5',\n",
        "    'PM10 (µg/m³)': 'pm10',\n",
        "    'NO (µg/m³)': 'no',\n",
        "    'NO2 (µg/m³)': 'no2',\n",
        "    'NOx (ppb)': 'nox',\n",
        "    'NH3 (µg/m³)': 'nh3',\n",
        "    'SO2 (µg/m³)': 'so2',\n",
        "    'CO (mg/m³)': 'co',\n",
        "    'Ozone (µg/m³)': 'ozone',\n",
        "    'Benzene (µg/m³)': 'benzene',\n",
        "    'Toluene (µg/m³)': 'toluene',\n",
        "    'Xylene (µg/m³)': 'xylene',\n",
        "    'O Xylene (µg/m³)': 'o_xylene',\n",
        "    'Eth-Benzene (µg/m³)': 'eth_benzene',\n",
        "    'MP-Xylene (µg/m³)': 'mp_xylene',\n",
        "    'AT (°C)': 'temp_c',\n",
        "    'RH (%)': 'rh_percent',\n",
        "    'WS (m/s)': 'ws_m_s',\n",
        "    'WD (deg)': 'wd_deg',\n",
        "    'RF (mm)': 'rf_mm',\n",
        "    'TOT-RF (mm)': 'tot_rf_mm',\n",
        "    'SR (W/mt2)': 'sr_w_mt2',\n",
        "    'BP (mmHg)': 'bp_mmHg',\n",
        "    'VWS (m/s)': 'vws_m_s',\n",
        "    'Timestamp': 'timestamp'\n",
        "}\n",
        "combined_df.rename(columns=new_columns, inplace=True)\n",
        "\n",
        "# Step 3: Handle missing values and convert data types.\n",
        "# Replace common representations of missing data with pandas' NaN.\n",
        "combined_df.replace(['', 'NA'], pd.NA, inplace=True)\n",
        "\n",
        "# Convert 'timestamp' to datetime and set it as the index.\n",
        "# Use errors='coerce' to turn invalid parsing into NaT (Not a Time).\n",
        "# Use format='mixed' and dayfirst=True to handle potential inconsistencies in timestamp format.\n",
        "combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'], errors='coerce', format='mixed', dayfirst=True)\n",
        "combined_df.set_index('timestamp', inplace=True)\n",
        "\n",
        "# Convert all relevant columns to numeric type, coercing errors to NaN.\n",
        "for col in combined_df.columns:\n",
        "    if col not in ['City']:\n",
        "        combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
        "\n",
        "# Step 4: Check for and drop duplicates.\n",
        "duplicates = combined_df.duplicated().sum()\n",
        "print(f\"Found {duplicates} duplicate rows.\")\n",
        "if duplicates > 0:\n",
        "    combined_df.drop_duplicates(inplace=True)\n",
        "    print(\"Dropped duplicate rows.\")\n",
        "\n",
        "\n",
        "combined_df.info()\n",
        "\n",
        "# Step 5: Resample the data to a daily average.\n",
        "# Group by city and then resample\n",
        "daily_df = combined_df.groupby('City').resample('D').mean()\n",
        "\n",
        "# The grouping creates a multi-index. Reset the index to make 'City' a column again.\n",
        "daily_df.reset_index(inplace=True)\n",
        "\n",
        "# You can save this cleaned and resampled data to a new CSV file.\n",
        "daily_df.to_csv('aqi_data.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(\"Head of the cleaned and resampled DataFrame:\")\n",
        "print(daily_df.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "daily_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# --- 1. Create proper DateTime index ---\n",
        "# If your original index is already datetime-like, skip this; otherwise:\n",
        "# Assuming the dataset has a datetime index or you can use row numbers as proxy\n",
        "daily_df = daily_df.copy()\n",
        "daily_df['DateTime'] = pd.date_range(start='2015-01-01', periods=len(daily_df), freq='D')\n",
        "daily_df.set_index('DateTime', inplace=True)\n",
        "\n",
        "# --- 2. Select main pollutants ---\n",
        "pollutants = ['pm2_5', 'pm10', 'no2', 'so2', 'co', 'ozone']\n",
        "\n",
        "# --- 3. Prepare anomaly summary dataframe ---\n",
        "anomaly_summary = pd.DataFrame(columns=['City', 'Pollutant', 'Date', 'Value', 'Event'])\n",
        "\n",
        "# --- 4. Loop through cities and pollutants ---\n",
        "for city in daily_df['City'].dropna().unique():\n",
        "    city_df = daily_df[daily_df['City'] == city]\n",
        "\n",
        "    for pollutant in pollutants:\n",
        "        ts = city_df[pollutant].dropna()\n",
        "\n",
        "        if len(ts) < 30:  # skip if not enough data\n",
        "            continue\n",
        "\n",
        "        # Seasonal decomposition with monthly period (30 days)\n",
        "        try:\n",
        "            decomp = seasonal_decompose(ts, model='additive', period=30)\n",
        "            residual = decomp.resid.dropna()\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        # Detect anomalies: mean + 1*std\n",
        "        threshold = residual.mean() + residual.std()\n",
        "        spikes = residual[residual > threshold]\n",
        "        if spikes.empty:\n",
        "            continue\n",
        "\n",
        "        # Classify events (basic rules)\n",
        "        for date in spikes.index:\n",
        "            event = \"\"\n",
        "            month = date.month\n",
        "            if month in [10, 11, 12, 1]:\n",
        "                event = \"Festival/Fireworks\"\n",
        "            if month in [10, 11]:\n",
        "                event = \"Crop Burning\"\n",
        "            if pd.Timestamp('2020-03-25') <= date <= pd.Timestamp('2020-05-31'):\n",
        "                event = \"Lockdown 2020\"\n",
        "\n",
        "            anomaly_summary = pd.concat([anomaly_summary,\n",
        "                                         pd.DataFrame({'City':[city], 'Pollutant':[pollutant],\n",
        "                                                       'Date':[date], 'Value':[ts[date]],\n",
        "                                                       'Event':[event]})], ignore_index=True)\n",
        "\n",
        "        # Optional: plot time series with anomalies\n",
        "        plt.figure(figsize=(12,4))\n",
        "        plt.plot(ts, label=f'{pollutant} in {city}')\n",
        "        plt.scatter(spikes.index, ts[spikes.index], color='red', label='Anomaly')\n",
        "        plt.title(f'{pollutant} Time Series with Anomalies - {city}')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel(pollutant)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "# --- 5. Display summary table ---\n",
        "print(\"Anomaly Summary:\")\n",
        "print(anomaly_summary)\n",
        "\n",
        "# Optional: save to CSV\n",
        "anomaly_summary.to_csv(\"Pollutant_Anomalies_Summary.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "K_lL27pgFO-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Select main pollutants\n",
        "pollutants = ['pm2_5', 'pm10', 'no2', 'so2', 'co', 'ozone']\n",
        "\n",
        "for pollutant in pollutants:\n",
        "    plt.figure(figsize=(12,6))\n",
        "    sns.boxplot(x='City', y=pollutant, data=daily_df)\n",
        "    plt.title(f'Spatial Distribution of {pollutant} Across Cities')\n",
        "    plt.xlabel('City')\n",
        "    plt.ylabel(pollutant)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Qr1v-wG9F6TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "import folium\n",
        "from geopy.geocoders import Nominatim\n",
        "import time\n",
        "\n",
        "print(daily_df.columns)\n",
        "\n",
        "# --- Visualization 1: Time-series Plot for PM2.5 ---\n",
        "plt.figure(figsize=(15, 7))\n",
        "for city, grp in daily_df.groupby('City'):\n",
        "    plt.plot(grp.index, grp['pm2_5'], label=city)\n",
        "\n",
        "plt.title(\"Daily PM2.5 Time-Series per City\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"PM2.5 (µg/m³)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- Visualization 2: Seasonal Boxplots ---\n",
        "def assign_season(month):\n",
        "    if month in [12, 1, 2]:\n",
        "        return \"Winter\"\n",
        "    elif month in [3, 4, 5]:\n",
        "        return \"Summer\"\n",
        "    elif month in [6, 7, 8, 9]:\n",
        "        return \"Monsoon\"\n",
        "    else:\n",
        "        return \"Post-Monsoon\"\n",
        "\n",
        "daily_df['Season'] = daily_df.index.month.map(assign_season)\n",
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=\"Season\", y=\"pm2_5\", data=daily_df, palette=\"Set2\")\n",
        "plt.title(\"Seasonal Distribution of PM2.5\")\n",
        "plt.show()\n",
        "\n",
        "# --- Visualization 3: Correlation Heatmap ---\n",
        "\n",
        "all_cols = ['pm2_5', 'pm10', 'no2', 'so2', 'ozone', 'co',\n",
        "            'temp_c', 'rh_percent', 'ws_m_s', 'rf_mm']\n",
        "corr = daily_df[all_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix: Pollutants & Meteorological Drivers\")\n",
        "plt.show()\n",
        "\n",
        "#####################################\n",
        "\n",
        "city_coords = {\n",
        "    \"Amravati\": (16.5131, 80.5165),\n",
        "    \"Anantpur\": (14.6824, 77.6017),\n",
        "    \"Chittoor\": (13.2172, 79.1003),\n",
        "    \"Rajamahendravaram\": (17.0005, 81.8040),\n",
        "    \"Tirupati\": (13.6288, 79.4192),\n",
        "    \"Vijayawada\": (16.5062, 80.6480),\n",
        "    \"Visakhapatnam\": (17.6868, 83.2185)\n",
        "    # add more cities as per your dataset\n",
        "}\n",
        "\n",
        "city_map = folium.Map(location=[15.9, 80.0], zoom_start=7)\n",
        "\n",
        "for city, grp in daily_df.groupby('City'):\n",
        "    if city in city_coords:\n",
        "        lat, lon = city_coords[city]\n",
        "        folium.Marker(\n",
        "            location=[lat, lon],\n",
        "            popup=city,\n",
        "            icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n",
        "        ).add_to(city_map)\n",
        "\n",
        "city_map.save(\"City_Map.html\")\n",
        "\n",
        "#####################################\n"
      ],
      "metadata": {
        "id": "aHRw2_3pemww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Table\n",
        "\n",
        "# Meteorological features\n",
        "met_features = ['temp_c', 'rh_percent', 'ws_m_s', 'rf_mm']\n",
        "\n",
        "# Pollutants\n",
        "pollutants = ['pm2_5', 'pm10', 'no2', 'so2', 'co', 'ozone']\n",
        "\n",
        "# Pearson correlation\n",
        "pearson_corr = daily_df[pollutants + met_features].corr(method='pearson')\n",
        "print(\"Pearson Correlation Table:\")\n",
        "print(pearson_corr.loc[pollutants, met_features])\n",
        "\n",
        "# Spearman correlation\n",
        "spearman_corr = daily_df[pollutants + met_features].corr(method='spearman')\n",
        "print(\"Spearman Correlation Table:\")\n",
        "print(spearman_corr.loc[pollutants, met_features])\n"
      ],
      "metadata": {
        "id": "FjCskSZcKXx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression Output\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import statsmodels.api as sm\n",
        "\n",
        "results_lr = {}\n",
        "\n",
        "for pollutant in pollutants:\n",
        "    data = daily_df[met_features + [pollutant]].dropna()\n",
        "    if len(data) < 30:\n",
        "        continue\n",
        "\n",
        "    X = data[met_features]\n",
        "    y = data[pollutant]\n",
        "\n",
        "    # Using statsmodels for detailed regression output\n",
        "    X_sm = sm.add_constant(X)  # add intercept\n",
        "    model = sm.OLS(y, X_sm).fit()\n",
        "\n",
        "    print(f\"\\nRegression Output for {pollutant}:\")\n",
        "    print(model.summary())\n",
        "\n",
        "    results_lr[pollutant] = model.rsquared  # variance explained"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o2hlqKAKidm",
        "outputId": "2979ae23-f2b2-42d3-d8d8-34c7565301f9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Regression Output for pm2_5:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  pm2_5   R-squared:                       0.130\n",
            "Model:                            OLS   Adj. R-squared:                  0.130\n",
            "Method:                 Least Squares   F-statistic:                     456.8\n",
            "Date:                Fri, 26 Sep 2025   Prob (F-statistic):               0.00\n",
            "Time:                        17:56:05   Log-Likelihood:                -55991.\n",
            "No. Observations:               12217   AIC:                         1.120e+05\n",
            "Df Residuals:                   12212   BIC:                         1.120e+05\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        122.8625      2.749     44.695      0.000     117.474     128.251\n",
            "temp_c        -1.4665      0.063    -23.161      0.000      -1.591      -1.342\n",
            "rh_percent    -0.5455      0.024    -22.745      0.000      -0.592      -0.498\n",
            "ws_m_s        -3.9765      0.184    -21.621      0.000      -4.337      -3.616\n",
            "rf_mm         -3.0724      0.750     -4.094      0.000      -4.543      -1.601\n",
            "==============================================================================\n",
            "Omnibus:                     6809.778   Durbin-Watson:                   0.332\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           182858.779\n",
            "Skew:                           2.158   Prob(JB):                         0.00\n",
            "Kurtosis:                      21.455   Cond. No.                         992.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "Regression Output for pm10:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                   pm10   R-squared:                       0.103\n",
            "Model:                            OLS   Adj. R-squared:                  0.103\n",
            "Method:                 Least Squares   F-statistic:                     351.6\n",
            "Date:                Fri, 26 Sep 2025   Prob (F-statistic):          5.66e-287\n",
            "Time:                        17:56:05   Log-Likelihood:                -63355.\n",
            "No. Observations:               12217   AIC:                         1.267e+05\n",
            "Df Residuals:                   12212   BIC:                         1.268e+05\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        195.4873      5.033     38.843      0.000     185.622     205.352\n",
            "temp_c        -0.9810      0.116     -8.463      0.000      -1.208      -0.754\n",
            "rh_percent    -1.1119      0.044    -25.324      0.000      -1.198      -1.026\n",
            "ws_m_s        -7.8446      0.336    -23.343      0.000      -8.503      -7.186\n",
            "rf_mm         -6.2970      1.370     -4.595      0.000      -8.983      -3.611\n",
            "==============================================================================\n",
            "Omnibus:                     5732.045   Durbin-Watson:                   0.303\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            87928.276\n",
            "Skew:                           1.861   Prob(JB):                         0.00\n",
            "Kurtosis:                      15.605   Cond. No.                         994.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "Regression Output for no2:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                    no2   R-squared:                       0.149\n",
            "Model:                            OLS   Adj. R-squared:                  0.149\n",
            "Method:                 Least Squares   F-statistic:                     536.0\n",
            "Date:                Fri, 26 Sep 2025   Prob (F-statistic):               0.00\n",
            "Time:                        17:56:05   Log-Likelihood:                -48892.\n",
            "No. Observations:               12253   AIC:                         9.779e+04\n",
            "Df Residuals:                   12248   BIC:                         9.783e+04\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         58.0617      1.516     38.291      0.000      55.089      61.034\n",
            "temp_c        -0.6123      0.035    -17.494      0.000      -0.681      -0.544\n",
            "rh_percent    -0.2030      0.013    -15.318      0.000      -0.229      -0.177\n",
            "ws_m_s        -3.3126      0.101    -32.687      0.000      -3.511      -3.114\n",
            "rf_mm         -0.1269      0.414     -0.306      0.759      -0.939       0.685\n",
            "==============================================================================\n",
            "Omnibus:                     5274.524   Durbin-Watson:                   0.197\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            32859.524\n",
            "Skew:                           1.972   Prob(JB):                         0.00\n",
            "Kurtosis:                       9.986   Cond. No.                         992.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "Regression Output for so2:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                    so2   R-squared:                       0.061\n",
            "Model:                            OLS   Adj. R-squared:                  0.061\n",
            "Method:                 Least Squares   F-statistic:                     198.7\n",
            "Date:                Fri, 26 Sep 2025   Prob (F-statistic):          2.33e-165\n",
            "Time:                        17:56:05   Log-Likelihood:                -38241.\n",
            "No. Observations:               12233   AIC:                         7.649e+04\n",
            "Df Residuals:                   12228   BIC:                         7.653e+04\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          1.7635      0.639      2.761      0.006       0.512       3.015\n",
            "temp_c         0.1316      0.015      8.943      0.000       0.103       0.160\n",
            "rh_percent     0.0392      0.006      7.033      0.000       0.028       0.050\n",
            "ws_m_s         0.9107      0.043     21.234      0.000       0.827       0.995\n",
            "rf_mm         -0.8440      0.175     -4.835      0.000      -1.186      -0.502\n",
            "==============================================================================\n",
            "Omnibus:                     4319.832   Durbin-Watson:                   0.481\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22754.371\n",
            "Skew:                           1.618   Prob(JB):                         0.00\n",
            "Kurtosis:                       8.845   Cond. No.                         990.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "Regression Output for co:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                     co   R-squared:                       0.065\n",
            "Model:                            OLS   Adj. R-squared:                  0.065\n",
            "Method:                 Least Squares   F-statistic:                     208.3\n",
            "Date:                Fri, 26 Sep 2025   Prob (F-statistic):          4.74e-173\n",
            "Time:                        17:56:05   Log-Likelihood:                -2047.9\n",
            "No. Observations:               12001   AIC:                             4106.\n",
            "Df Residuals:                   11996   BIC:                             4143.\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          1.1174      0.034     33.293      0.000       1.052       1.183\n",
            "temp_c        -0.0102      0.001    -12.956      0.000      -0.012      -0.009\n",
            "rh_percent    -0.0013      0.000     -4.479      0.000      -0.002      -0.001\n",
            "ws_m_s        -0.0418      0.002    -18.253      0.000      -0.046      -0.037\n",
            "rf_mm         -0.0278      0.009     -3.059      0.002      -0.046      -0.010\n",
            "==============================================================================\n",
            "Omnibus:                    13594.679   Durbin-Watson:                   0.402\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4339179.073\n",
            "Skew:                           5.414   Prob(JB):                         0.00\n",
            "Kurtosis:                      95.522   Cond. No.                         991.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "Regression Output for ozone:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  ozone   R-squared:                       0.157\n",
            "Model:                            OLS   Adj. R-squared:                  0.157\n",
            "Method:                 Least Squares   F-statistic:                     556.1\n",
            "Date:                Fri, 26 Sep 2025   Prob (F-statistic):               0.00\n",
            "Time:                        17:56:05   Log-Likelihood:                -50845.\n",
            "No. Observations:               11964   AIC:                         1.017e+05\n",
            "Df Residuals:                   11959   BIC:                         1.017e+05\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        121.3899      1.999     60.715      0.000     117.471     125.309\n",
            "temp_c        -1.7421      0.047    -36.940      0.000      -1.835      -1.650\n",
            "rh_percent    -0.6544      0.018    -37.191      0.000      -0.689      -0.620\n",
            "ws_m_s         2.5151      0.135     18.693      0.000       2.251       2.779\n",
            "rf_mm         -1.2631      0.537     -2.351      0.019      -2.316      -0.210\n",
            "==============================================================================\n",
            "Omnibus:                     1011.800   Durbin-Watson:                   0.246\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1506.894\n",
            "Skew:                           0.668   Prob(JB):                         0.00\n",
            "Kurtosis:                       4.113   Cond. No.                         998.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance (Random Forest example)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "\n",
        "feature_importances = pd.DataFrame(index=met_features)\n",
        "\n",
        "for pollutant in pollutants:\n",
        "    data = daily_df[met_features + [pollutant]].dropna()\n",
        "    if len(data) < 30:\n",
        "        continue\n",
        "\n",
        "    X = data[met_features]\n",
        "    y = data[pollutant]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    fi = rf.feature_importances_\n",
        "    feature_importances[pollutant] = fi\n",
        "\n",
        "# Display feature importances\n",
        "print(\"Feature Importances (Random Forest):\")\n",
        "print(feature_importances)"
      ],
      "metadata": {
        "id": "ZYXIkruWKzB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# --- 1. Prepare features and target ---\n",
        "data = daily_df[['pm2_5', 'ws_m_s', 'temp_c', 'rh_percent', 'rf_mm']].dropna()\n",
        "\n",
        "X = data[['ws_m_s', 'temp_c', 'rh_percent', 'rf_mm']].dropna()\n",
        "y = data['pm2_5'].loc[X.index]  # ensure indices match\n",
        "\n",
        "# --- 2. Train-test split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- 3. Scale features ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# --- 4. Build ANN model ---\n",
        "model = Sequential([\n",
        "    Dense(16, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(1)  # output layer for regression\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X_train_scaled, y_train, epochs=100, batch_size=16, verbose=0)\n",
        "\n",
        "# --- 5. Predictions ---\n",
        "y_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "mask = ~np.isnan(y_test) & ~np.isnan(y_pred)\n",
        "y_test_clean = y_test[mask]\n",
        "y_pred_clean = y_pred[mask]\n",
        "\n",
        "# --- 6. Model evaluation ---\n",
        "r2 = r2_score(y_test_clean, y_pred_clean)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_clean, y_pred_clean))  # manual sqrt\n",
        "print(f\"R²: {r2:.3f}, RMSE: {rmse:.3f}\")\n",
        "\n",
        "# --- 7. Diagnostic plots ---\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Predicted vs Actual\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, y_pred, alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.title(\"Predicted vs Actual\")\n",
        "\n",
        "# Residuals vs Predicted\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_pred, residuals, alpha=0.6)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residuals vs Predicted\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qge6Si109h5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}