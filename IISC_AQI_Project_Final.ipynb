{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwKu8nmRpvEE7oFAF4duYx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johny85/World-of-Scripts/blob/master/IISC_AQI_Project_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0G4QkEvb2tv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Step 1: Read all the CSV files and combine them into a single DataFrame.\n",
        "file_list = glob.glob('*.csv')\n",
        "\n",
        "# Initialize an empty list to store the DataFrames.\n",
        "df_list = []\n",
        "\n",
        "# Loop through each file, read it into a DataFrame and add a 'City' column.\n",
        "for file in file_list:\n",
        "    city_name = file.replace('.csv', '')\n",
        "    df = pd.read_csv(file)\n",
        "    df['City'] = city_name\n",
        "    df_list.append(df)\n",
        "\n",
        "# Concatenate all the DataFrames into one.\n",
        "combined_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Step 2: Standardize column names.\n",
        "new_columns = {\n",
        "    'PM2.5 (µg/m³)': 'pm2_5',\n",
        "    'PM10 (µg/m³)': 'pm10',\n",
        "    'NO (µg/m³)': 'no',\n",
        "    'NO2 (µg/m³)': 'no2',\n",
        "    'NOx (ppb)': 'nox',\n",
        "    'NH3 (µg/m³)': 'nh3',\n",
        "    'SO2 (µg/m³)': 'so2',\n",
        "    'CO (mg/m³)': 'co',\n",
        "    'Ozone (µg/m³)': 'ozone',\n",
        "    'Benzene (µg/m³)': 'benzene',\n",
        "    'Toluene (µg/m³)': 'toluene',\n",
        "    'Xylene (µg/m³)': 'xylene',\n",
        "    'O Xylene (µg/m³)': 'o_xylene',\n",
        "    'Eth-Benzene (µg/m³)': 'eth_benzene',\n",
        "    'MP-Xylene (µg/m³)': 'mp_xylene',\n",
        "    'AT (°C)': 'temp_c',\n",
        "    'RH (%)': 'rh_percent',\n",
        "    'WS (m/s)': 'ws_m_s',\n",
        "    'WD (deg)': 'wd_deg',\n",
        "    'RF (mm)': 'rf_mm',\n",
        "    'TOT-RF (mm)': 'tot_rf_mm',\n",
        "    'SR (W/mt2)': 'sr_w_mt2',\n",
        "    'BP (mmHg)': 'bp_mmHg',\n",
        "    'VWS (m/s)': 'vws_m_s',\n",
        "    'Timestamp': 'timestamp'\n",
        "}\n",
        "combined_df.rename(columns=new_columns, inplace=True)\n",
        "\n",
        "# Step 3: Handle missing values and convert data types.\n",
        "# Replace common representations of missing data with pandas' NaN.\n",
        "combined_df.replace(['', 'NA'], pd.NA, inplace=True)\n",
        "\n",
        "# Convert 'timestamp' to datetime and set it as the index.\n",
        "# Use errors='coerce' to turn invalid parsing into NaT (Not a Time).\n",
        "# Use format='mixed' and dayfirst=True to handle potential inconsistencies in timestamp format.\n",
        "combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'], errors='coerce', format='mixed', dayfirst=True)\n",
        "combined_df.set_index('timestamp', inplace=True)\n",
        "\n",
        "# Convert all relevant columns to numeric type, coercing errors to NaN.\n",
        "for col in combined_df.columns:\n",
        "    if col not in ['City']:\n",
        "        combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
        "\n",
        "# Step 4: Check for and drop duplicates.\n",
        "duplicates = combined_df.duplicated().sum()\n",
        "print(f\"Found {duplicates} duplicate rows.\")\n",
        "if duplicates > 0:\n",
        "    combined_df.drop_duplicates(inplace=True)\n",
        "    print(\"Dropped duplicate rows.\")\n",
        "\n",
        "\n",
        "combined_df.info()\n",
        "\n",
        "# Step 5: Resample the data to a daily average.\n",
        "# Group by city and then resample\n",
        "daily_df = combined_df.groupby('City').resample('D').mean()\n",
        "\n",
        "# The grouping creates a multi-index. Reset the index to make 'City' a column again.\n",
        "daily_df.reset_index(inplace=True)\n",
        "\n",
        "# You can save this cleaned and resampled data to a new CSV file.\n",
        "daily_df.to_csv('aqi_data.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(\"Head of the cleaned and resampled DataFrame:\")\n",
        "print(daily_df.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "daily_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# Re-load the cleaned data if you are starting a new notebook session\n",
        "# daily_df = pd.read_csv('aqi_data.csv', index_col='timestamp', parse_dates=True)\n",
        "\n",
        "print(daily_df.columns)\n",
        "print(combined_df.columns)\n",
        "\n",
        "# --- Visualization 1: Time-series Plot for PM2.5 ---\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.lineplot(data=daily_df, x=daily_df.index, y='pm2_5')\n",
        "plt.title('PM2.5 Levels Over Time (Daily Average)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('PM2.5 (µg/m³)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('Time-series Plot for PM2.5.png')\n",
        "\n",
        "# --- Visualization 2: Seasonal Boxplots ---\n",
        "daily_df.index = pd.to_datetime(daily_df.index)\n",
        "daily_df['month'] = daily_df.index.month\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.boxplot(x='month', y='pm2_5', data=daily_df)\n",
        "plt.title('Monthly PM2.5 Levels')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('PM2.5 (µg/m³)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('Seasonal_Boxplots.png')\n",
        "\n",
        "# --- Visualization 3: Correlation Heatmap ---\n",
        "pollutants = ['pm2_5', 'pm10', 'no2', 'so2', 'ozone', 'co']\n",
        "meteorological = ['temp_c', 'rh_percent', 'ws_m_s', 'rf_mm']\n",
        "all_cols = pollutants + meteorological\n",
        "correlation_matrix = daily_df[all_cols].corr(method='pearson')\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Pollutants and Meteorological Drivers')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('Correlation Heatmap.png')\n",
        "\n",
        "# --- Seasonal Decomposition ---\n",
        "city_data = daily_df[daily_df['City'] == 'Amravati']['pm2_5'].dropna()\n",
        "decomposition = seasonal_decompose(city_data, model='additive', period=365)\n",
        "decomposition.plot()\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.suptitle('Seasonal Decomposition of PM2.5 for Amravati', y=1.02)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('Seasonal Decomposition.png')"
      ],
      "metadata": {
        "id": "aHRw2_3pemww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import visualkeras\n",
        "\n",
        "# --- Part 1: Correlation Analysis ---\n",
        "# Example for PM2.5 and temperature\n",
        "corr_data = daily_df[['pm2_5', 'temp_c']].dropna()\n",
        "pm25_temp_pearson = pearsonr(corr_data['pm2_5'], corr_data['temp_c'])\n",
        "pm25_temp_spearman = spearmanr(corr_data['pm2_5'], corr_data['temp_c'])\n",
        "print(f\"Pearson Correlation (PM2.5 vs Temp): r={pm25_temp_pearson.statistic:.2f}, p-value={pm25_temp_pearson.pvalue:.2e}\")\n",
        "print(f\"Spearman Correlation (PM2.5 vs Temp): rho={pm25_temp_spearman.statistic:.2f}, p-value={pm25_temp_spearman.pvalue:.2e}\")\n",
        "\n",
        "# --- Part 2: Regression Analysis (PM2.5 vs Meteorological Drivers) ---\n",
        "features = ['temp_c', 'rh_percent', 'ws_m_s', 'rf_mm']\n",
        "target = 'pm2_5'\n",
        "regression_data = daily_df.dropna(subset=features + [target])\n",
        "X = regression_data[features]\n",
        "y = regression_data[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"\\nLinear Regression Model Performance:\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\") # This is your % variance explained!\n",
        "\n",
        "# --- Part 3: ANN for 7-day Prediction (conceptual outline) ---\n",
        "# This only shows a basic ANN setup.\n",
        "# Scaling the data before feeding it to the ANN.\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the ANN model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1)) # Output layer for a single value prediction\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2, verbose=0)\n",
        "print(\"\\nANN Model Training Complete.\")\n",
        "\n",
        "visualkeras.layered_view(model).show() # display using your system viewer"
      ],
      "metadata": {
        "id": "OymcGPVGfdQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}